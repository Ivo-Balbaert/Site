<imports />

<page ns="c-blog" path="blog/next-gen-memory-model">
<main>
<title>Universal Speed, Safety and Simplicity in Vale</title>
<subtitle>Generational memory management and cross-platform goodness!</subtitle>

<date-and-author date="August 31st, 2020" author="Evan Ovadia and Eske Hansen" />

<section>
  <p>
    Welcome to Vale!
  </p>
</section>

<split>
  <half>
    <section>
      <p>
        Vale is a very new language (announced just last month, in fact!), with modern features and a focus on easy, readable syntax, and a very nice, gradual learning curve.
      </p>
      <p>
        Vale's goal is to show the world that <b>speed and safety can be easy,</b> that we don't have to make the choice between fast languages and easy languages, we can have both!
      </p>
      <p>
        Vale has some fascinating syntactical designs (<a href="https://vale.dev/ref/structs#shortcalling">shortcalling</a>, <a href="https://vale.dev/ref/interfaces#sealedconstructors">interface constructors</a>, <a href="https://vale.dev/ref/references#inline">the inl keyword</a>, and more!) that will make life easier, but Vale's true power is underneath the surface, in the most important part of any programming language: <b>how it handles memory.</b>
      </p>
    </section>

  </half>
  <half>
    <vale>
fn main() {
  a = 3;
  b = 5;
  c = a + b;
  println("Behold the ancient " + c);
}
    </vale>
    <br />
    <vale>
fn main() {
  x str = "world!";
  println("Hello " + x);
}
    </vale>
    <br />
    <vale>
struct Spaceship {
  name Str;
  numWings Int;
}

fn main() {
  ship = Spaceship("Serenity", 2);
  println(ship.name);
}
    </vale>
  </half>
</split>

<section>
  <p>
    Every other language uses a form of reference counting, garbage collection, or borrow checking. As part of the <a href="https://repl.it/jam">repl.it hackathon</a>, we created something <b>completely new</b> for Vale, something we call <b>Hybrid-Generational Memory,</b> which is over <i>twice as fast</i> as reference-counting! <n>fastmidaslink</n>
  </p>
  <p>
    Our efforts didn't stop there, though. Also during the hackathon, we took it <i>even further</i> and showed that an incredibly fast language like Vale can be seamlessly cross-compiled to other platforms, like Javascript. <n>fastvalejslink</n>
  </p>
  <p>
    With this, we've taken our first step towards Vale's true vision: <b>universal speed, safety, and simplicity!</b>
  </p>
</section>

<h2>Speed and Safety: Hybrid-Generational Memory</h2>

<section>
<split>
  <width60>

    <p>
      If you know what you're doing, coming back to C from Java feels <i>amazing.</i> C's raw speed and simplicity is truly wonderful. Java is like riding a freight train, but C is like driving a Ferrari.
    </p>
    <p>
      Trains have their benefits though; they're much safer than cars. Even though it's slow, Java code is safer because you can't trigger undefined behavior or seg-faults, and you generally make more secure code.
    </p>
    <p>
      If only there was a way to <b>easily have both speed and safety!</b> Previous attempts (Cyclone, ATS, Rust, Ada) have all resulted in languages with a very difficult learning curve. But is there a way to have speed, safety, <i>and</i> simplicity?
    </p>
    <p>
      Yes there is! With its single ownership and high-level nature, Vale can have something we call <b>Hybrid-Generational Memory,</b> a memory model based on generation numbers. It's a revolutionary new memory model, which completely avoids reference-counting's aliasing costs, garbage collection's pauses, and borrow checkers' difficulty.
    </p>
    <p>
      Over the last three weeks, we implemented the basic idea. We designed seven stages of optimization to avoid branching and increase cache-friendliness to get maximum speed. If you're interested in the details, you can read about the full design at <a href="/blog/hybrid-generational-memory-part-1">Hybrid-Generational Memory.</a>
    </p>

  </width60>
  <width40>
    <table width="100%" className={ns("comparison")}>
      <thead>
        <tr>
          <th colspan="3">Fast Languages,<br/>Safety and Simplicity</th>
        </tr>
        <tr>
          <th className={ns("na")}></th>
          <th className={ns("na")}>Easy</th>
          <th className={ns("na")}>Difficult</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th className={ns("na")}>Safe</th>
          <td className={ns("good")}>Vale</td>
          <td className={ns("meh")}>Rust</td>
        </tr>
        <tr>
          <th className={ns("na")}>Unsafe</th>
          <td className={ns("meh")}>C</td>
          <td className={ns("bad")}>C++</td>
        </tr>
      </tbody>
    </table>
    <br />

    <table width="100%" className={ns("comparison")}>
      <thead>
        <tr>
          <th colspan="3">Safe Languages,<br/>Simplicity and Speed</th>
        </tr>
        <tr>
          <th className={ns("na")}></th>
          <th className={ns("na")}>Easy</th>
          <th className={ns("na")}>Difficult</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th className={ns("na")}>Fast</th>
          <td className={ns("good")}>Vale</td>
          <td className={ns("meh")}>Rust</td>
        </tr>
        <tr>
          <th className={ns("na")}>Slow</th>
          <td className={ns("meh")}>Python</td>
          <td className={ns("bad")}>Java</td>
        </tr>
      </tbody>
    </table>
    <br />

    <table width="100%" className={ns("comparison")}>
      <thead>
        <tr>
          <th colspan="3">Simple Languages,<br/>Safety and Speed</th>
        </tr>
        <tr>
          <th className={ns("na")}></th>
          <th className={ns("na")}>Safe</th>
          <th className={ns("na")}>Unsafe</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th className={ns("na")}>Fast</th>
          <td className={ns("good")}>Vale</td>
          <td className={ns("meh")}>C</td>
        </tr>
        <tr>
          <th className={ns("na")}>Slow</th>
          <td className={ns("meh")}>Python</td>
          <td className={ns("bad")}>Swift</td>
        </tr>
      </tbody>
    </table>

  </width40>
</split>

<p>
  We were shocked to see that it was <b>way faster</b> than reference-counting, even without optimizations! <n>benchmarks</n>
</p>
</section>
<section>
<table className={ns("comparison")}>
  <thead>
    <tr>
      <th>Mode</th>
      <th>Speed&nbsp;(seconds)</th>
      <th>Overhead Compared to Unsafe (seconds)</th>
      <th>Overhead Compared to Unsafe (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th className={ns("na")}>Naive&nbsp;RC&nbsp;<sup style={{fontWeight: "normal"}}>1</sup></th>
      <td className={ns("bad")}>54.90&nbsp;seconds</td>
      <td className={ns("bad")}>+11.08&nbsp;seconds</td>
      <td className={ns("bad")}>+25.29%</td>
    </tr>
    <tr>
      <th className={ns("na")}>Naive&nbsp;HGM&nbsp;<sup style={{fontWeight: "normal"}}>2</sup></th>
      <td className={ns("good")}>48.57&nbsp;seconds</td>
      <td className={ns("good")}>+4.75&nbsp;seconds</td>
      <td className={ns("good")}>+10.84%</td>
    </tr>
    <tr>
      <th className={ns("na")}>Unsafe&nbsp;<sup style={{fontWeight: "normal"}}>3</sup></th>
      <td className={ns("na")}>43.82&nbsp;seconds</td>
      <td className={ns("na")}>n/a</td>
      <td className={ns("na")}>n/a</td>
    </tr>
  </tbody>
</table>
</section>
<section>
<div style={{margin: "0 32px"}}>
  <p>
    <sup>1</sup> <b>Naive RC</b>: A basic reference counting mode, to keep an object alive while there are still references alive. Basic reference counting adds 25.29% to the run time of a program, compared to Unsafe mode!
  </p>
  <p>
    <sup>2</sup> <b>Naive HGM</b>: a basic hybrid-generational memory implementation, where before each dereference, we compare generations to see if the object is still alive. It only adds 10.84% to the run time of a program! <n>faster</n>
  </p>
  <p>
    <sup>3</sup> <b>Unsafe</b>: A mode that has no memory safety, which compiles to roughly the same assembly code that would come from C.
  </p>
</div>
</section>
<section>
<p>
   Hybrid-Generational Memory only adds 10.84% to the run time of a program, <b>less than half the cost of reference counting!</b>
</p>
<p>
  When we started, we thought Hybrid-Generational Memory would be better than reference counting, but we were blown away by how much. And even better, this is <i>before</i> the optimizations!
</p>
</section>
<section>
  If you'd like to run this for yourself, <a href="https://github.com/Verdagon/Vale/raw/replitfinal/bundle/ValeCompiler0.0.8.zip">you can find this experimental version of the Vale compiler here!</a> It includes the benchmark program, and instructions on running it, in the <b>benchmark</b> folder. <n>ubuntu</n>
</section>
<section>
<p>
  After we add our optimizations, we expect speed on par with Rust, and almost as fast as C++! We'll be submitting benchmarks and a full publication to <a href="https://en.wikipedia.org/wiki/OOPSLA">OOPSLA (Object-Oriented Programming, Systems, Languages & Applications)</a>, so stay tuned!
</p>
</section>

<h2>Clean Cross-Compilation</h2>

<section>
<p>
  Vale's new memory model is incredibly fast, which makes it an amazing choice for games and servers. But why stop there? Vale could bring its speed to <i>even higher</i> realms, such as <b>app development,</b> because it is the first native-speed language that can do <b>clean cross-compilation.</b>
</p>
<p>
  After writing an app for one platform (Web, iOS, Android), we often look longingly at the other platforms, and wish we could just re-use our code on those. Unfortunately, existing methods for sharing code between platforms often suffer:
</p>
<ul>
  <li>
    Heavy slowdowns, as we run GC'd languages on iOS without their trusty JIT-compiler, such as Java or Kotlin.
  </li>
  <li>
    Difficulty communicating between JVM and a native language like C++ or Rust, as well as the difficulties of learning how to code safely with those languages.
  </li>
</ul>
<p>
  <b>If only there was a fast and easy language that didn't suffer these problems!</b> If only there was a language that could cleanly operate across the VM/native boundary. It's the missing piece of the puzzle, a holy grail of cross-platform development.
</p>
<p>
  We recently realized that Vale's <a href="https://vale.dev/blog/raii-next-steps">true single ownership</a> paradigm could be the missing puzzle piece!
</p>
<p>
  To put it concisely, Vale's single ownership and <a href="https://vale.dev/blog/zero-cost-refs-regions">regions</a> can work together to make it very easy to cross-compile to another language (JS, Java, Swift) and, with one keyword, compile to native assembly to take advantage of Vale's true speed. You can read more about this at <a href="/blog/cross-platform-core-vision">Vision for the Cross-Platform Core</a>.
</p>
<p>
  To make that vision work, we needed to cross-compile Vale to a VM language, like Javascript. This is usually <b>very difficult,</b> as most native-speed languages (like C++) give you raw access to the memory, and VM languages like Javascript do not.
</p>
<p>
  However, Vale is a native-speed language that's designed to be simple and high-level. For example, it has references instead of pointers, and, like Python, it doesn't expose raw memory.
</p>
<p>
  We decided to start with compiling Vale to Javascript, and after three weeks of effort, <b>it worked!</b> <a href="https://repl.it/@ForkedLightning/ForkedLightningWeb">You can try it out at the Forked Lightning repl.it.</a> <n>forkedlightning</n>
</p>
</section>

<section>
<p>
  <b>This is a big step forward,</b> because every other language incurs a big cost when cross-compiling:
</p>
<ul>
  <li>
    Garbage-collected languages like Java or Kotlin bring their costly garbage collector to iOS, and they also have to run without their Just-In-Time Compilers, causing them to be even slower.
  </li>
  <li>
    Reference counted languages like Swift, if compiled to JVM or JS, would suffer the cost of garbage collection <i>and</i> reference counting, because weak references and destructors rely on reference-counting precision.
  </li>
  <li>
    Low-level languages like C++ or Rust, if compiled to JVM or JS, would need to have "simulated RAM", like what powers asm.js, causing big slowdowns.
  </li>
</ul>
<p>
  Because single ownership fits so cleanly into native, reference-counting, and garbage-collected environments, Vale suffers <b>zero</b> extra slowdowns when cross-compiling.
</p>
<p>
  With this, Vale has done the impossible, <b>clean cross-compilation</b>, and has cleared the way towards a future with <b>fast cross-platform code.</b>
</p>
</section>

<h2>Next Steps</h2>

<section>
<p>
  Now that we have prototypes of Vale's two core innovations, we'll be spending the next few months building on these foundations:
</p>
<ul>
  <li>
    Add the next seven stages of optimization for Hybrid-Generational Memory, to see it reach its true speed potential!
  </li>
  <li>
    Add Swift and Java cross-compilation!
  </li>
  <li>
    Implement basic ID-based regions, so we can have automatic references across the JVM/native and JS/WASM boundaries!
  </li>
</ul>
<p>
  We'll also be:
</p>
<ul>
  <li>
    Adding IDE support!
  </li>
  <li>
    Making the foundations solid, doing some refactors to prepare for the big features ahead!
  </li>
  <li>
    Releasing Vale v0.1 with a big splash!
  </li>
  <li>
    Completely replacing C++ over the next decade. Easy!
  </li>
</ul>
<p>
  If you want to see this happen sooner, or just want to contribute to something cool, we invite you to <a href="/contribute">come join us!</a> <n>help</n>
</p>
<p>
  Stay tuned for coming articles, where we talk about Vale's optimizations, pentagonal tiling, and more. If you want to learn more before then, come by the <a href="http://reddit.com/r/vale">r/Vale subreddit</a> or the <a href="https://discord.gg/SNB8yGH">Vale discord server!</a>
</p>

</section>

<div className={ns("afterword")}>
  <h2 className={ns("noline")} style={{marginTop: 0}}>Afterword: Hackathon and Scope</h2>

  <p>These past three weeks in the repl.it hackathon have been a wild ride, full of late-night design discussions on discord, insanity-driven optimization brainstorming, and caffeine-fueled all-nighters!</p>

  <p>Vale's vision is vast, and too big to fit in three weeks, so we knew at the very beginning that we needed to keep scope down, and really nail the core concepts that show Vale's potential.</p>

  <p>
    Here's what we did specifically:
  </p>
  <ul>
    <li>
      Implemented a basic to-JS cross-compiler, <b>ValeJS</b>, starting with printing a simple string.
    </li>
    <li>
      Modified the compiler's intermediate AST to include enough information for ValeJS to successfully construct structs.
    </li>
    <li>
      Created a way for ValeJS to mimic Vale's edge-based vtables in Javascript.
    </li>
    <li>
      Made a way for ValeJS to fill arrays without exposing null/undefined in the Vale's intermediate AST.
    </li>
    <li>
      Finished ValeJS, and made a little roguelike (a room and an @ sign) to show it off.
    </li>
    <li>
      Implemented "unsafe mode" in the compiler's native backend ("Midas"), so we could get an accurate measurement for how much overhead the other modes have.
    </li>
    <li>
      Made a web-service for repl.it to talk to, which outputs Vale's intermediate AST, so ValeJS could turn it into Javascript.
    </li>
    <li>
      Implemented "naive RC mode" in Midas, so we could measure our new mode against the native memory management standard.
    </li>
    <li>
      Made a way to simplify the very long and complicated names from the Vale's intermediate AST to something simple that JS could handle.
    </li>
    <li>
      Implemented "Resilient V0 mode" in Midas, which turned all constraint references into weak references, using a central table for all weak ref counts.
    </li>
    <li>
      Implemented "Resilient V1 mode" in Midas, which had a similar central table, but for generations.
    </li>
    <li>
      Implemented "Resilient V2 mode" in Midas, with the "generational heap" which embeds generations directly into the memory allocations themselves.
    </li>
  </ul>
  <p>
    Here's what wasn't part of the three weeks:
  </p>
  <ul>
    <li>
      The basic compiler, compiling to LLVM, existed before the hackathon.
    </li>
    <li>
      The seven stages of optimization are planned for the next few months. That's right, we beat RC without any optimizations!
    </li>
    <li>
      Unfinished features, which we paused when we started the hackathon:
      <ul>
        <li>
          Regions, as described in <a href="https://vale.dev/blog/zero-cost-refs-regions">Zero-Cost References with Regions</a>.
        </li>
        <li>
          <a href="https://vale.dev/ref/structs">shortcalling struct</a> and <a href="https://vale.dev/ref/interfaces">interface constructors</a> is unfinished.
        </li>
        <li>
          <a href="https://vale.dev/ref/references">The inl keyword</a> is mostly implemented but not hooked up to all types yet.
        </li>
      </ul>
    </li>
  </ul>

  <h2 className={ns("noline")} style={{marginTop: 0}}>Appendix: Benchmark Numbers</h2>

  <p>
    We ran the raw numbers for each mode 7 times, and got the following numbers:
  </p>
  <ul>
    <li>Unsafe mode: <b>43.82s</b>, 43.89s, 43.90s, 44.06s, 44.28s, 44.65s, 44.83s</li>
    <li>Naive RC: <b>54.90s</b>, 55.17s, 55.27s, 55.32s, 55.34s, 55.37s, 55.48s</li>
    <li>Resilient v2: <b>48.57s</b>, 48.91s, 49.18s, 49.19s, 49.46s, 49.59s, 51.87s</li>
  </ul>
  <p>
    We then used the best number for each run (bolded above).
  </p>

  <p>
    To avoid CPU caching effects, we ran this on a very large map (200 x 200), specified in main.vale.
  </p>

</div>

</main>

<margin>

<Note name="fastmidaslink">
  You can find this experimental version of the compiler <a href="https://github.com/Verdagon/Vale/raw/replitfinal/bundle/ValeCompiler0.0.8.zip">here</a>! (Ubuntu only, for now)
</Note>

<Note name="fastvalejslink">
  You can try this cross-compiling goodness out <a href="https://repl.it/@ForkedLightning/ForkedLightningWeb">here!</a>
</Note>


<Note name="benchmarks">
  These numbers were from compiling a Vale <a href="https://github.com/Verdagon/Vale/tree/replitfinal/bundle/benchmark">cellular automata and flood-connecting roguelike terrain generator,</a> with different compilation modes.
</Note>

<Note name="forkedlightning">
  Forked lightning was our team name in the <a href="https://blog.repl.it/langjam">repl.it Language Jam!</a>
</Note>

<Note name="ubuntu">
  This includes a binary of the Vale compiler, built for 64-bit Ubuntu. If you'd like a build for a different OS, come by the <a href="https://discord.gg/SNB8yGH">Vale discord</a>!
</Note>

<Note name="faster">
  We actually noticed even faster results for our method (down to 6.8% overhead) when we ran smaller benchmarks, probably because those smaller benchmarks fit entirely in the cache. The main numbers in the table were run with a much larger data set.
</Note>

<Note name="help">
  <p>All contributions are welcome! Soon, we're going to:</p>
  <ul>
    <li>Finish designing the region borrow checker!</li>
    <li>Implement the bump allocator and pooling!</li>
    <li>Write a standard library! (sets, hash maps, lists, etc)</li>
    <li>Make syntax highlighters! (VSCode, Sublime, Vim, Emacs, etc)</li>
    <li>Enable support gdb/lldb for debugging!</li>
    <li>Add better error reporting!</li>
    <li>Replace the temporary combinator-based parser with a real one!</li>
    <li>Add a "show all constraint refs" option in debug mode to our LLVM codegen stage!</li>
  </ul>
  <p>If any of this interests you, come join us!</p>
</Note>

</margin>
</page>

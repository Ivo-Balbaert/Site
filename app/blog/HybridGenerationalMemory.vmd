---
title: Vale's Hybrid-Generational Memory
subtitle: For speed and simplicity!
author: Evan Ovadia and Theo Watkins
date: Nov 24 2020
realm: blog
path: blog/hybrid-generational-memory
layout: annotated
namespace: c-blog m-annotated
---


Vale's *hybrid-generational memory* is a new ground-breaking memory model that combines all the best parts of existing memory strategies: it's as easy as garbage collection, as deterministic as reference counting, and as fast as borrow checking. [#resilient]


We'll be publishing a series of articles soon which explain the model much more fully and understandably. *This page is is a draft, here for those that want an early explanation.*


*Warning:* We're packing several articles' worth of explanation into a very dense single page. Only read this if you're familiar with free-lists, generational indices, thread-local storage, borrow checking, atomicity, fat pointers, branch misprediction, and cache misses!


If you have any questions, feel free to come by the [discord server](https://discord.gg/SNB8yGH) and we'll be happy to explain the model fully.


# Explaining HGM


For the purpose of explanation, we'll start with something inefficient and simple, and add in more and more optimizations.


## Setting the Stage


We'll start with Vale's unsafe-fast mode. Recall:

 * Every object is owned by an owning reference (like {unique_ptr}). When the owning reference goes away, the object is freed.
 * We can have non-owning references ("constraint references") to an object as well.
 * For now, every allocation is on the heap, nothing on the stack yet.
 * Each thread's memory (like Rust and Lobster) is isolated; any given object is only visible to one thread at a time.


<notes>
#resilient: Vale has three release modes:

 * Resilient mode, which is fast and memory safe; it will halt the program when we try to dereference a freed object.
 * Assist mode, for development, to detect potential problems even earlier.
 * Unsafe mode, which turns off all safety.

Resilient mode uses hybrid-generational memory.
</notes>


## Adding Generational Malloc.


Next, we add in [Generational Malloc](/blog/generational-malloc).

 * Every heap allocation has a u48 generation number before the object. [#uint]
 * Constraint references contain a raw pointer and a u48 "target generation" number.
 * Before dereferencing an object, assert that the target generation number matches the allocation's generation number.


<notes>
#uint: u48 means a 48-bit unsigned integer.
</notes>


## Eliminate Most Liveness Checks

Use static analysis to reduce the number of liveness checks as much as possible. For example:

 * For each dereference, figure out if an in-scope local indirectly owns it. If so, skip the liveness check.
 * Automatically track this information through intermediate stores/loads from struct members, where possible.
 * Automatically track this information through function calls like an automtic borrow checker, where possible.


## Hybridize Where Beneficial


Add a u16 counter to every allocation, next to the u48 generation number.

 * When the object is allocated, the u16 RC will be 1.
 * When an owning reference disappears, only deallocate if the counter is 1 (branch predicting true).
 * *When the compiler can guarantee it to be a net benefit*, such as when we dereference a local reference >3 times, do one liveness check and turn that local into an owning reference, thus:
    * Incrementing and decrementing the RC. [# Normally, this RCing incurs cache misses. Here, it's not a miss, because it's an object we're dereferencing anyway.]
    * At scope end, deallocating if the counter is 1 (branch predicting false).
    * Eliminating all liveness checks within the scope.


<notes/>


## Stack Allocations


Now we'll introduce stack-allocated objects and the Local Generation Table:

 * In every stack allocation, before the object, is a u47 index into a thread-global {vector<[u48, u16]>} called the Local Generation Table (LGT). [# {[u48, u16]} means a pair, with a u48 and a u16.]
    * The u48 is the generation number for a stack object.
    * The u16 is the RC for a stack object.
 * Deallocating a stack object will increment the u48 and use the u16 to add this "open space" to a free-list. [#freelist]
 * Stack allocated objects needn't check their RC before freeing. [# This is because the above RC incrs/decrs are tied to particular scopes.]
 * Add a u1 isHeap to each reference. If true, referred object is on the heap, else it's on the stack.
 * Add a u47 "LGT index" to each reference. If it's a stack object, it's used to hold the index into the LGT.
 * To get a generation from a reference:
    * If isHeap true, look at the top of the allocation. Else, look in the LGT at the index contained in the u47.
    * The above can be turned into multiply and add.


<notes>
#freelist: The LGT's free-list has a touch of sorcery. The LGT is divided into 2^16-entry chunks. The u16 in each entry describes where in this chunk the next open space is. The first entry in this chunk is special; its u48 contains not a generation number but instead the index of the next chunk that's completely full of open spaces. In this way, the LGT has a free-list of free-lists.
</notes>


## Inline Objects


Now we'll support objects containing other objects inline. The only complication is that inline objects are not right after their allocation's generation.

 * Add a u15 to the reference, an offset from the object's start to the allocation's generation.


## Reducing Reference Size


Our references so far contain a pointer, a u48, a {u1}, a u47, and a u16, totalling to 176 bytes. Let's reduce that to 128 bytes. [# A reference being 128b might seem unusual, but this is the width of C++'s {std::unique_ptr<T>}, {std::shared_ptr<T>}, {std::weak_ptr<T>}, and the default size of {generational_arena}'s {Index}.] Start by keeping the {u1} isHeap.

 * If isHeap true, the reference contains the 64b pointer, the u48 (target generation), and the u15 offset.
 * If isHeap false, the reference contains a 32b pointer (relative to stack start), the u48 (target generation), and the u15 offset, and the 47b LGT index.


## Pointer Bit-Sorcery


Assuming these structs:

```
struct GenerationAndRc {
  u48 gen;
  u16 rc;
}

struct GenRef {
  u48 targetGeneration;
  u1 isHeap;
  union {
    struct { u15 offsetFromPtr; void* heapObjPtr; } whenHeap;
    struct { u47 lgtIndex; u32 relativeAddrFromStack; } whenStack;
  };
}
```


We would get a reference's generation like so:

```
uint48_t getGeneration(GenRef ref) {
  if (ref.isHeap) {
    return ((GenerationAndRc*)(ref.obj - ref.offset))->gen;
  } else {
    return lgt[ref.lgtIndex].gen;
  }
}
```


<notes/>


However, that might incur some branching costs. We can instead do some adding and multiplying with the isHeap boolean: [#defeat]

```
uint48_t getGeneration(GenRef ref) {
  return ref.isHeap * ((GenerationAndRc*)(ref.obj - ref.offset))->gen +
    (!ref.isHeap) * lgt[ref.lgti].gen;
}
```


That's basically it! There are some more things we could do to speed it up even more, using virtual memory, regions, or more static analysis, but we'll stop the explanation here.


<notes>
#defeat: This causes problems for the optimizer. We'll likely need to implement our own optimization pass to run after the other passes for this benefit to be realized.
</notes>


# Minor Extra Details

To address some frequently asked questions:

 * When we move something across thread boundaries, we must recurse through and:
    * Increment all the generation numbers, effectively cutting off access to the rest of this thread.
    * Assert the RC is zero; assert that there are no locals pointing at the object.
 * Objects from other threads must be annotated with the {mig}ratory keyword. Instead of freeing these objects, they're sent back to their original thread for deallocation, to avoid race conditions.
 * When a generation number hits the maximum, don't use that generation number anymore; the LGT shouldnt use it, and genFree shouldn't let it be reused. genFree can slice up the allocation into smaller ones that don't include the initial 8b.


<notes/>


# Potential Weaknesses

Some potential weaknesses to explore:

 * Limits:
    * Individual structs cannot be larger than 32kb.
    * Limited to 2^95 stack allocations over the lifetime of the thread (a 5ghz processor would take at least 268 million years to hit this limit).
       * Note: we could increase the struct size limit if we lower the stack allocations limit.
 * The pointer magic might prevent some LLVM optimizations, in which case we'll need our own optimization pass.
 * Storing the generation number at the top of a <=64b allocation means a liveness check won't incur an extra cache miss since we're about to dereference the object anyway, and the entire object is on one cache line. However, for larger objects, it does incur an extra cache miss. Most objects are small, but programs with an unusually large proportion of medium sized objects not in an array could suffer a small performance hit.
 * Having a separate heap per size class could increase fragmentation. This might be mitigating by using the regular malloc() and free() for large structs.


<notes/>


# How might it compare to Rust?


Vale is a high-level language with zero {unsafe}, so an apples-to-apples comparison would be with a Rust where the only {unsafe} is in the standard library and generational_arena.


Memory safety is never free, except for the most trivial of programs. Cyclone, Rust, ATS, Fortran, and every other language incurs _some_ overhead to ensure safety. This comes in the form of branching and cache miss costs, for example in:

 * Array bounds checks.
 * Check if something's still alive, e.g. with booleans or generation liveness checks.
 * Reference count increments/decrements.

Or large memory costs, for example if objects are stored in vectors.


Rust programs uses borrow references where they can, and otherwise use {Rc} or generational indices to get around the borrow checker, which incurs run-time overhead.


Vale produces a similar result, but from a very different direction. Vale starts by using generation checks, but then removes the vast majority of them using static analysis and by strategically inserting ref-counting where it would eliminate even more generation checks.

In the end, this results in most references being borrow references, with a few remaining Rc operations and generation checks, which looks surprisingly like hand-written Rust code.


<notes/>


In practice, Rust programs make heavy use of arenas and pools. Hybrid-generational memory doesn't force the programmer one way or the other, but Vale separately offers regions to accomplish the same thing.


<notes/>


There are other differences between Rust and Vale which could factor into a comparison:

 * Rust objects often require wrapping in RefCell to address mutability, which incurs some branching cost. Vale doesn't have this particular cost.
 * The borrow checker knows exactly when something can be mutated. Vale's read-only references and static analysis accomplish much of the same thing, but the borrow checker is more accurate and might optimize more.
 * Rust has various tricks (such as Cell) which, while not being universally applicable, can be used in certain situations to reduce cost.
 * It would be much easier in Vale to use a bump or pool allocator for all allocations in a scope. Rust also makes some heap allocations which can't be tied to a given allocator.
 * Rust's Rc uses the heap, whereas Vale's objects and counts are always in the current region.


<notes/>


Time will tell how hybrid-generational memory compares with the borrow checker!
